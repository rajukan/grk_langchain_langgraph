{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:05:59.239030Z",
     "start_time": "2025-10-11T20:05:59.222718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "def _set_env_from_file(var: str, file_path: str = \"openai_key.txt\"):\n",
    "    \"\"\"\n",
    "    Reads an API key from a specified file and sets it as an environment variable.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        try:\n",
    "            # The 'with open' statement ensures the file is closed automatically\n",
    "            with open(file_path, 'r') as f:\n",
    "                # Read the first line and strip any leading/trailing whitespace\n",
    "                key = f.readline().strip()\n",
    "\n",
    "            if key:\n",
    "                os.environ[var] = key\n",
    "                print(f\"Successfully loaded {var} from {file_path}\")\n",
    "            else:\n",
    "                print(f\"Warning: {file_path} is empty.\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Key file not found at {file_path}. Please create the file.\")\n",
    "\n",
    "# --- Execution ---\n",
    "# Set the environment variable OPENAI_API_KEY from the file\n",
    "_set_env_from_file('OPENAI_API_KEY',file_path=\"../../keys/openai.txt\")\n",
    "_set_env_from_file('TAVILY_API_KEY',file_path=\"../../keys/tavily\")"
   ],
   "id": "3f21fed8eb0b31db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded TAVILY_API_KEY from ../../keys/tavily\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:02:14.983221Z",
     "start_time": "2025-10-11T20:02:14.980327Z"
    }
   },
   "cell_type": "code",
   "source": "MODEL=\"openai:gpt-4.1\"",
   "id": "5ddf7710760b4486",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# %pip install langchain-openai",
   "id": "13f8c2e5f1868d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:05:17.225485Z",
     "start_time": "2025-10-11T20:05:17.221873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph,START,END,MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain.chat_models import init_chat_model"
   ],
   "id": "32cbb8193001cca3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:06:09.036951Z",
     "start_time": "2025-10-11T20:06:09.020518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "llm = init_chat_model(model=MODEL)\n",
    "web_search_tool = TavilySearch(max_results=2)\n",
    "tools=[web_search_tool]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "def chatbot(state:MessagesState):\n",
    "    print(f\"Starting chatbot with {state}\")\n",
    "    print(f\"chatbot invoking {state['messages']}\")\n",
    "    return {\"messages\" : [llm_with_tools.invoke(state['messages'])]}"
   ],
   "id": "9bd4c0aa856c3e9c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:06:13.039119Z",
     "start_time": "2025-10-11T20:06:13.013394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "graph_builder.add_node(\"chatbot\",chatbot)\n",
    "graph_builder.add_node(\"tools\",tool_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition\n",
    ")\n",
    "\n",
    "graph_builder.add_edge(\"tools\",\"chatbot\")\n",
    "graph_builder.add_edge(START,\"chatbot\")\n",
    "graph = graph_builder.compile()"
   ],
   "id": "e80016d6015bdc61",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:06:30.193846Z",
     "start_time": "2025-10-11T20:06:30.189285Z"
    }
   },
   "cell_type": "code",
   "source": "print(graph.get_graph().print_ascii());",
   "id": "6744b9d73755df8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \r\n",
      "        | __start__ |         \r\n",
      "        +-----------+         \r\n",
      "               *              \r\n",
      "               *              \r\n",
      "               *              \r\n",
      "          +---------+         \r\n",
      "          | chatbot |         \r\n",
      "          +---------+         \r\n",
      "          .         .         \r\n",
      "        ..           ..       \r\n",
      "       .               .      \r\n",
      "+---------+         +-------+ \r\n",
      "| __end__ |         | tools | \r\n",
      "+---------+         +-------+ \n",
      "None\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:07:18.743478Z",
     "start_time": "2025-10-11T20:07:12.779191Z"
    }
   },
   "cell_type": "code",
   "source": "output = graph.invoke({\"messages\" : [\"Explain what you understand with confidence intervals in statistics\"]})",
   "id": "26206867e89c330d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chatbot with {'messages': [HumanMessage(content='Explain what you understand with confidence intervals in statistics', additional_kwargs={}, response_metadata={}, id='e0094448-bda4-454f-8beb-7c946bd74fbe')]}\n",
      "chatbot invoking [HumanMessage(content='Explain what you understand with confidence intervals in statistics', additional_kwargs={}, response_metadata={}, id='e0094448-bda4-454f-8beb-7c946bd74fbe')]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:07:36.466737Z",
     "start_time": "2025-10-11T20:07:36.461010Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "7401318962e10f47",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain what you understand with confidence intervals in statistics', additional_kwargs={}, response_metadata={}, id='e0094448-bda4-454f-8beb-7c946bd74fbe'),\n",
       "  AIMessage(content='A **confidence interval** in statistics is a range of values, derived from sample data, that is likely to contain the true value of an unknown population parameter (such as the mean or proportion). It provides an estimate of uncertainty around the sample statistic.\\n\\n### Key Points:\\n- **Interval Estimate:** Unlike a single-point estimate (e.g., \"the average height is 170 cm\"), a confidence interval gives a range (e.g., \"the true average height is likely between 168 cm and 172 cm\").\\n- **Confidence Level:** The confidence interval is associated with a confidence level, usually expressed as a percentage (commonly 90%, 95%, or 99%). A 95% confidence interval means that if we were to take many samples and compute intervals the same way, about 95% of those intervals would contain the true population parameter.\\n- **Interpretation:** A 95% confidence interval for the mean tells us that we are 95% confident that the interval contains the true mean. It does **not** mean there is a 95% probability that this one calculated interval contains the true value; rather, the method used gives intervals that capture the parameter 95% of the time in repeated samples.\\n- **Calculation:** Confidence intervals are often calculated using the sample mean (or proportion), the standard error (a measure of variability), and the critical value from the appropriate statistical distribution (like the z-score or t-score).\\n\\n#### Example\\nSuppose you survey 100 people, and the average amount of time they exercise per week is 4 hours, with a 95% confidence interval of [3.5, 4.5] hours. This means you can be 95% confident that the true average exercise time for the whole population lies between 3.5 and 4.5 hours per week.\\n\\n**In summary:**  \\nA confidence interval is a statistical tool for expressing uncertainty in estimates, giving a range in which the true value likely falls, together with an associated level of confidence.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 409, 'prompt_tokens': 1277, 'total_tokens': 1686, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_e24a1fec47', 'id': 'chatcmpl-CPa9xer9apQVK58HCHopcvh8TB0Iv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--cae77dc1-ec94-45f3-9f12-b3967289a474-0', usage_metadata={'input_tokens': 1277, 'output_tokens': 409, 'total_tokens': 1686, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:09:13.822471Z",
     "start_time": "2025-10-11T20:09:13.815309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ],
   "id": "58a6b46a44b88b0",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:15:17.798647Z",
     "start_time": "2025-10-11T20:15:14.778885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "config = {\"configurable\":{\"thread_id\":\"1\"}}\n",
    "user_input =\"Sup i am a llm enthusiast\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\" : [{\n",
    "        \"role\":\"user\",\n",
    "        \"content\":user_input,}]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "id": "848c41836885ef0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Sup i am a llm enthusiast\n",
      "Starting chatbot with {'messages': [HumanMessage(content='Sup i am a llm enthusiast', additional_kwargs={}, response_metadata={}, id='8a135ea8-755a-4118-bab2-cd0aa877508c')]}\n",
      "chatbot invoking [HumanMessage(content='Sup i am a llm enthusiast', additional_kwargs={}, response_metadata={}, id='8a135ea8-755a-4118-bab2-cd0aa877508c')]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hey! That’s awesome—large language models (LLMs) are such a fascinating field with so much happening right now. Are you working on any projects, research, or just exploring the tech? Let me know if you want to discuss models, prompting, fine-tuning, or anything else!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T20:17:55.778494Z",
     "start_time": "2025-10-11T20:17:52.793506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_input =\"What is my enthusiasm?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\":\"user\",\"content\":user_input}]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "id": "4db013497bf51896",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is my enthusiasm?\n",
      "Starting chatbot with {'messages': [HumanMessage(content='Sup i am a llm enthusiast', additional_kwargs={}, response_metadata={}, id='8a135ea8-755a-4118-bab2-cd0aa877508c'), AIMessage(content='Hey! That’s awesome—large language models (LLMs) are such a fascinating field with so much happening right now. Are you working on any projects, research, or just exploring the tech? Let me know if you want to discuss models, prompting, fine-tuning, or anything else!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 1275, 'total_tokens': 1336, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_e24a1fec47', 'id': 'chatcmpl-CPaHkOFnMxAvFm1fqHcm8ePySWaHQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b70c5aa9-85a2-4a57-8311-9620db3beeac-0', usage_metadata={'input_tokens': 1275, 'output_tokens': 61, 'total_tokens': 1336, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='What is my enthusiasm?', additional_kwargs={}, response_metadata={}, id='9f8b6ffa-e08e-41cd-88d9-afba610e6924')]}\n",
      "chatbot invoking [HumanMessage(content='Sup i am a llm enthusiast', additional_kwargs={}, response_metadata={}, id='8a135ea8-755a-4118-bab2-cd0aa877508c'), AIMessage(content='Hey! That’s awesome—large language models (LLMs) are such a fascinating field with so much happening right now. Are you working on any projects, research, or just exploring the tech? Let me know if you want to discuss models, prompting, fine-tuning, or anything else!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 1275, 'total_tokens': 1336, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_e24a1fec47', 'id': 'chatcmpl-CPaHkOFnMxAvFm1fqHcm8ePySWaHQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b70c5aa9-85a2-4a57-8311-9620db3beeac-0', usage_metadata={'input_tokens': 1275, 'output_tokens': 61, 'total_tokens': 1336, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='What is my enthusiasm?', additional_kwargs={}, response_metadata={}, id='9f8b6ffa-e08e-41cd-88d9-afba610e6924')]\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your enthusiasm is for large language models (LLMs)! You mentioned you’re a “llm enthusiast,” which means you’re interested and excited about the field of LLMs—these are advanced AI models capable of understanding and generating human-like language (like GPT-4, PaLM, Llama, etc.). \n",
      "\n",
      "If you want to chat about recent breakthroughs, applications, how to work with LLMs, or nerd out about technical details, I’m here for it! Would you like to dive deeper into any particular aspect?\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65f285d5bdccf914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "21fccbf05cd682d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "22ea257846e1f5d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ff955536108dbddd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e3f68ada8dc04c01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8eb5e5569a3703c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4b76776892ed8c95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3ce75c53631e6c6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "25b57994824f61d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2b291ec640d13995",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "87c32a7f3db68e71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "134f59d186fcdb4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "98b7bd610a4bc43a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8c935cd794cab33c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d8658ece82a746c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9cd8250ba07f6557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fe1199e502c6bd3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e124a11c2e84c02d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4d0f280b55e87964",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9345ff0bb4e762c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3e18c1f084c04c3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "533b09c88065adb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3fcd3c318df7b15f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1952a79611a4b733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "df0a1ae8b8ece935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1afc6bc81b39fab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "83f86cada6c78c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65f40e096fabfadb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d52f3ed200274e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "63292151f163d42b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a4d93fbaf3124cde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "116851ac0396f09f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e440f73f2be9a7d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "af15f35c4191fa3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c3c7fec9e5eae34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "132e635052e32f03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fbedea44586ccb7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ae8ba48539b2a91f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1505055547fce441",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
